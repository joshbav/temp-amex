TESTING FALCO IN A DOCKER IN DOCKER USE CASE, WHERE THE CONTAINER BEING BUILT HAS /ETC TOUCHED
Q:CAN WE DETECT THAT? OR WILL THE WEIRDNESS OF A DOCKER BUILD PREVENT IT?
A:CAN'T DETECT IT

eksctl create cluster --name joshbtest1 --region us-west-1 --zones=us-west-1a,us-west-1b --nodes 1 --node-type t3.xlarge --node-volume-size 60 --ssh-access --version=1.16 --tags owner=joshb --instance-prefix joshb --set-kubeconfig-context --nodegroup-name joshbtest1 --node-labels owner=joshb --ssh-public-key aws-personal


Made new image joshbav/temp-amex from
FROM centos:8
USER nobody

./build # pushed it to dockerhub

made nobody.yaml deployment that runs it and only does a sleep command as first test of falco rule

sysdig rules editor
   copy open_write to be amex_open_write - edit it to remove "and fd.num>=0"
   copy write_etc_common to be amex_write_etc_common
       edit it to use amex_open_write instead of open_write

rules library
    choose write below etc, copy
    rename to amex write below etc
    change condition to be amex_write_etc_common 

runtime policies
   add new policy named amex write below etc, 
   add description,
   scope to containers only (no namespaces yet)
   import amex write below etc from falco library, delete existing falco rule

loaded sysdig agent to eks cluster:

1. kubectl create ns sysdig-agent

2. FILL IN: kubectl -n sysdig-agent create secret generic sysdig-agent --from-literal=access-key=<your sysdig access key>

3. kubectl apply -n sysdig-agent -f https://raw.githubusercontent.com/draios/sysdig-cloud-scripts/master/agent_deploy/kubernetes/sysdig-agent-clusterrole.yaml

4. kubectl create serviceaccount sysdig-agent -n sysdig-agent

5. kubectl create clusterrolebinding sysdig-agent --clusterrole=sysdig-agent --serviceaccount=sysdig-agent:sysdig-agent

6. curl -sSLO https://raw.githubusercontent.com/draios/sysdig-cloud-scripts/master/agent_deploy/kubernetes/sysdig-agent-configmap.yaml

7. vi sysdig-agent-configmap.yaml  and add the correct collector URL per: https://docs.sysdig.com/en/saas-regions-and-ip-ranges.html

8. kubectl apply -n sysdig-agent -f sysdig-agent-configmap.yaml

7. kubectl apply -n sysdig-agent -f https://raw.githubusercontent.com/draios/sysdig-cloud-scripts/master/agent_deploy/kubernetes/sysdig-agent-daemonset-v2.yaml

8. curl -sSLO https://raw.githubusercontent.com/draios/sysdig-cloud-scripts/master/agent_deploy/kubernetes/sysdig-image-analyzer-configmap.yaml

9. vi sysdig-image-analyzer-configmap.yaml   and add the endpoint URL per: https://docs.sysdig.com/en/saas-regions-and-ip-ranges.html

10. kubectl apply -n sysdig-agent -f sysdig-image-analyzer-configmap.yaml

11: kubectl apply -n sysdig-agent -f https://raw.githubusercontent.com/draios/sysdig-cloud-scripts/master/agent_deploy/kubernetes/sysdig-image-analyzer-daemonset.yaml

# done installing agent

k apply -f nobody.yaml
k get pods 
k exec -it falcotest-6c88bcc788-8m2xh -- bash
touch /etc/blah
verify in secure's events screen that it fired (did first time)

k delete -f nobody.yaml

I tried using the dind pod but got a file mount error with the docker socket,
  decided to just use docker for now and come back to this.


ssh -i ~/aws-personal.pem ec2-user@ec2-3-101-131-45.us-west-1.compute.amazonaws.com
    ls -l /var/run/docker.sock   to see the docker socket was there, it was
    docker run --privileged -it -v /var/run/docker.sock:/var/run/docker.sock docker:dind sh
    touch /etc/blah
    verify in secure events that it showed up (it did, as expected)

    mkdir a && cd a && echo test>test.conf && echo "FROM hello-world" > Dockerfile && echo "ADD test.conf /etc" >> Dockerfile && docker build -t test . && docker run test
 
    verify in secure events that it showed up (it did NOT, THAT'S A PROBLEM)

    exit

    back in aws host now
    rm -rf a
    mkdir a && cd a && echo test>test.conf && echo "FROM docker:dind" > Dockerfile && echo "ADD test.conf /etc" >> Dockerfile && echo "RUN /bin/sleep 120" >> Dockerfile
    
    (startup up another ssh session, sudo bash, come back to this session)
    
    (startup up third ssh session, sudo bash, come back to this session)
    
    docker build -t test . --no-cache
    switch to second terminal session
        cd to /var/run/docker/tmp
        ls
        saw only 2 files, not filesystem or /etc
        ls /var/lib/docker/tmp/
            didnt see them there either
        
    switched to third terminal session
        docker ps
        saw new container being built, so it exists during this time while it sleeps
        waited for build to complete
        docker images (saw test image)

Conclusion: The docker build temp container is not seen by falco
next step: get a second opinion

eksctl delete cluster -n joshbtest1 -r us-west-1    


*******
hunting source code for docker build, hints:
https://github.com/docker/engine/blob/master/docs/api/v1.41.yaml#L7213

Build()  mentioned in engine/integration-cli/cli/cli.go
 so now lets find all files not containing test in their name and search their contents for Build(
 find . -type f \( ! -iname "*test*" \) | xargs grep -i "Build("

client/image_build.go seems the most promising.
  func (cli *Client) ImageBuild(     seems to be the ideal focus
  so it send to the deamon cli.postRaw(ctx, "/build"....

now on to find the daemon code where the build happens...
  grep "postRaw" daemon didn't find anything

daemon/images/image_builder.go
  func (i *ImageService) CreateImage(  looks promising
  it seems to call imageStore.Create(config) which makes the image,
  then what I assume is the created image is returned.
  So I need to focus on imageStore.Create
    that turns out to be defined as image.Store in ImageService strut
    and I think I can find that in https://github.com/moby/moby/blob/master/image/image.go
    yes its at https://github.com/moby/moby/blob/master/image/image.go#L66
       it contains V1Image which is just image config info
       it also contains rawJSON []byte  which I'm wondering might be the filesystem/image being built and that's what we're hunting for
       below I see // MarshalJSON serializes the image to JSON. which supports that idea
       seeing the .rawJSON used as the return in NewFromJSON() also kinda supports this, see https://github.com/moby/moby/blob/master/image/image.go#L250
       

https://github.com/moby/moby/blob/master/image/fs.go  is also interesting but is it used for docker builds though?

https://github.com/moby/moby/blob/master/image/store.go  says it's an interface for creating and accessing images, so that's interesting, but is it used during docker build or docker run/pull? "creating images" could mean creating the ephemeral filesystem after extracting the layers and combining them....




  

  
  so now to find that








